# 📝 NLP Learn and Build — Phase Tracker

This file tracks my learning progress, topics, notes, projects, and next steps for each phase.

---

## Phase 1: Foundations & Data Formats 🗂️

### Topics Covered
- Introduction to NLP and key concepts 🤖
- Common data formats: CSV, JSON, Parquet, XML, SQL 📊
- Reading and writing CSV & Parquet files using Pandas and PySpark 🐍
- Basic data inspection and validation ✔️

### Notes & Challenges
- Understood the pros and cons of different data formats
- Faced challenges with large Parquet files in PySpark, solved by partitioning
- Learned to automate data ingestion pipelines

### Mini Projects
- [x] Read and process CSV files with Pandas
- [x] Spark ingestion script to load Parquet data
- [ ] Implement data validation pipeline for CSV and JSON

### Useful Tools & Libraries
- Pandas  
- PySpark  
- Fastparquet  
- SQLAlchemy  

### Next Steps
- Deep dive into text cleaning techniques  
- Explore regex for text preprocessing  
- Begin hands-on exercises in `2-text-cleaning/`  

---

## Phase 2: Text Cleaning & Preprocessing 🧹

### Topics Covered
- Regex basics and advanced patterns  
- Emoji removal and normalization  
- Language detection libraries  
- Text tokenization and normalization  

### Notes & Challenges
- To be updated...

### Mini Projects
- To be updated...

### Useful Tools & Libraries
- regex  
- emoji  
- langdetect  
- NLTK / SpaCy  

### Next Steps
- Explore feature engineering techniques (TF-IDF, embeddings)  
- Work on mini projects with real datasets  

---

## Phase 3: Feature Engineering & Classical ML ⚙️📈

*(Add content as you progress)*

---

